from langchain_openai import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage
import streamlit as st #le asignamos un alias es streamlit
from langchain.prompts import PromptTemplate
import streamlit as st


# #Conf la pagina de la app
st.set_page_config(page_title="Chatbot Educativo ", page_icon="ğŸ¤–") 
st.title("ğŸ¤– Chat para el COLEGIO PIO XII - DespeÃ±aderos-")
st.markdown("Este es un *chatbot escolar* . Â¡Arranquemos!") #aÃ±adimos descripcion txt

#agregamos una barra para configurar TEMPERATURA Y LLM A ELEGIR
with st.sidebar:
    st.header("ConfiguraciÃ³n")
    temperature = st.slider("Creatividad", 0.0, 1.0, 0.5, 0.1)
    model_name = st.selectbox("Modelo", ["gpt-4", "gpt-4o-mini", "gpt-5"])

#configuramos y definimos el modelo
    chat_model = ChatOpenAI(model=model_name, temperature=temperature)


#Memoria, implementacion
#1-comprobar si hay mensajes
if "mensajes" not in st.session_state:
    st.session_state.mensajes = []

 #  BotÃ³n para limpiar historial
if st.button("ğŸ§¹ Nueva conversaciÃ³n"):
    st.session_state.mensajes = ""
    st.success("Historial limpiado correctamente âœ…")
    st.rerun()

#creamos el template
prompt_template = PromptTemplate(
    input_variables=["mensaje", "historial"],
    template="""
Eres un asistente Ãºtil, amigable y profesional llamado ChatBoti. 
Tu objetivo es ayudar al usuario de forma clara, empÃ¡tica y precisa, 
manteniendo coherencia con el contexto previo.

Historial de conversaciÃ³n:
{historial}

Usuario: {mensaje}

ChatBot Pro:"""
)

#cremos la cadena
cadena = prompt_template|chat_model

#si hay mensajes previos, los mostramos en la interfaz
for msg in st.session_state.mensajes:
    rol = "assistant" if isinstance(msg, AIMessage) else "user" if isinstance(msg, HumanMessage) else "system"
    with st.chat_message(rol):
        st.markdown(msg.content)

#cuadro de entrada de txt de usuario
pregunta = st.chat_input("Escribe tu mensaje: ")

# if pregunta:
#     #mostramos el mensaje por pantalla
#     with st.chat_message("user"):
#         st.markdown(pregunta)
    #almacenamos en la memoria
    # st.session_state.mensajes.append(HumanMessage(content=pregunta))

    #generar la respuesta usando el llm
    # respuesta = chat_model.invoke(st.session_state.mensajes)

    #mostrar la rta en la interfaz
    
    # with st.chat_message("assistant"):
    #     st.markdown(respuesta.content)

    # #lo aÃ±ado a la memoria
    # st.session_state.mensajes.append(respuesta) 

if pregunta:
    with st.chat_message("user"):
        st.markdown(pregunta)
    
    try:
        with st.chat_message("assistant"):
            response_placeholder = st.empty() #contenedor vacio
            full_response = ""
 
            # Â¡AquÃ­ estÃ¡ la magia del streaming!
            for chunk in cadena.stream({"mensaje": pregunta, "historial": st.session_state.mensajes}):
                full_response += chunk.content
                response_placeholder.markdown(full_response + "â–Œ")  # El cursor parpadeante
            
            response_placeholder.markdown(full_response)
        
        # No olvides almacenar los mensajes
        st.session_state.mensajes.append(HumanMessage(content=pregunta))
        st.session_state.mensajes.append(AIMessage(content=full_response))
        
    except Exception as e:
        # Â¿QuÃ© tipo de errores podrÃ­an ocurrir aquÃ­?
        st.error(f"Error al generar respuesta: {str(e)}")
        st.info("Verifica que tu API Key de OpenAI estÃ© configurada correctamente.")

# FOOTER
st.divider()
st.caption("ğŸ« Colegio Pio XII - DespeÃ±aderos")       














# import os
# from langchain_openai import ChatOpenAI
# from langchain.schema import AIMessage, HumanMessage, SystemMessage
# import streamlit as st
# from langchain.prompts import PromptTemplate

# # ============================================================================
# # CONFIGURACIÃ“N INICIAL
# # ============================================================================

# st.set_page_config(
#     page_title="Chatbot Escolar - Colegio Pio XII",
#     page_icon="ğŸ¤–",
#     layout="centered",
#     initial_sidebar_state="expanded"
# )

# # ============================================================================
# # FUNCIONES AUXILIARES
# # ============================================================================

# def inicializar_sesion():
#     """Inicializa el estado de la sesiÃ³n con valores por defecto"""
#     if "mensajes" not in st.session_state:
#         st.session_state.mensajes = [
#             SystemMessage(content=(
#                 "Eres FerChus, un asistente educativo del Colegio Pio XII en DespeÃ±aderos, CÃ³rdoba. "
#                 "Eres amigable, paciente y ayudas con dudas escolares de todas las materias. "
#                 "Respondes de forma clara, didÃ¡ctica y motivadora."
#             ))
#         ]
#     if "contador_mensajes" not in st.session_state:
#         st.session_state.contador_mensajes = 0


# def obtener_historial_formateado(max_mensajes=10):
#     """
#     Formatea el historial de mensajes para el prompt.
#     Limita a los Ãºltimos N mensajes para no exceder tokens.
#     """
#     mensajes_recientes = st.session_state.mensajes[-max_mensajes:]
#     historial = []
    
#     for msg in mensajes_recientes:
#         if isinstance(msg, SystemMessage):
#             continue
#         elif isinstance(msg, HumanMessage):
#             historial.append(f"Estudiante: {msg.content}")
#         elif isinstance(msg, AIMessage):
#             historial.append(f"FerChus: {msg.content}")
    
#     return "\n".join(historial) if historial else "No hay conversaciÃ³n previa."


# def limpiar_conversacion():
#     """Reinicia la conversaciÃ³n manteniendo solo el mensaje de sistema"""
#     mensaje_sistema = st.session_state.mensajes[0]
#     st.session_state.mensajes = [mensaje_sistema]
#     st.session_state.contador_mensajes = 0


# def validar_api_key():
#     """Verifica que la API key de OpenAI estÃ© configurada"""
#     if not os.getenv("OPENAI_API_KEY"):
#         st.error("âš ï¸ **Error:** No se encontrÃ³ OPENAI_API_KEY en las variables de entorno")
#         st.info("ğŸ’¡ Configura tu API key antes de usar el chatbot")
#         st.code("export OPENAI_API_KEY='tu-api-key-aqui'", language="bash")
#         st.stop()

# # ============================================================================
# # INTERFAZ PRINCIPAL
# # ============================================================================

# # ============================================================================
# # INICIALIZACIÃ“N TEMPRANA (antes del sidebar)
# # ============================================================================

# inicializar_sesion()

# # TÃ­tulo y descripciÃ³n
# st.title("ğŸ¤– Chat Educativo - Colegio Pio XII")
# st.markdown("**DespeÃ±aderos, CÃ³rdoba** | Asistente: *FerChus* ğŸ“š")
# st.divider()

# # ============================================================================
# # SIDEBAR - CONFIGURACIÃ“N
# # ============================================================================

# with st.sidebar:
#     st.header("âš™ï¸ ConfiguraciÃ³n")
    
#     # BotÃ³n de reset (siempre en la parte superior)
#     if st.button("ğŸ§¹ Nueva conversaciÃ³n", key="reset_btn", use_container_width=True):
#         limpiar_conversacion()
#         st.rerun()
    
#     st.divider()
    
#     # ConfiguraciÃ³n del modelo
#     temperature = st.slider(
#         "ğŸ’¡ Creatividad",
#         min_value=0.0,
#         max_value=1.0,
#         value=0.7,
#         step=0.1,
#         help="Mayor valor = respuestas mÃ¡s creativas"
#     )
    
#     model_name = st.selectbox(
#         "ğŸ¤– Modelo",
#         options=["gpt-4o-mini", "gpt-4o"],
#         index=0,
#         help="gpt-4o-mini es mÃ¡s rÃ¡pido y econÃ³mico"
#     )
    
#     st.divider()
    
#     # EstadÃ­sticas
#     st.caption("ğŸ“Š **EstadÃ­sticas**")
#     num_mensajes = len([m for m in st.session_state.mensajes if not isinstance(m, SystemMessage)])
#     st.caption(f"ğŸ’¬ Mensajes: {num_mensajes // 2}")

# # ============================================================================
# # VALIDACIÃ“N Y CONFIGURACIÃ“N DEL MODELO
# # ============================================================================

# validar_api_key()

# # Crear prompt template optimizado
# prompt_template = PromptTemplate(
#     input_variables=["mensaje", "historial"],
#     template="""Eres FerChus, un asistente educativo amigable del Colegio Pio XII.

# Contexto de la conversaciÃ³n:
# {historial}

# Pregunta del estudiante: {mensaje}

# Responde de manera clara, didÃ¡ctica y motivadora. Si es un tema complejo, usa ejemplos."""
# )

# # Crear modelo y cadena
# try:
#     chat_model = ChatOpenAI(model=model_name, temperature=temperature)
#     cadena = prompt_template | chat_model
# except Exception as e:
#     st.error(f"âŒ Error al inicializar el modelo: {str(e)}")
#     st.stop()

# # ============================================================================
# # MOSTRAR HISTORIAL
# # ============================================================================

# for msg in st.session_state.mensajes:
#     if isinstance(msg, SystemMessage):
#         continue
    
#     role = "assistant" if isinstance(msg, AIMessage) else "user"
#     avatar = "ğŸ¤–" if role == "assistant" else "ğŸ‘¤"
    
#     with st.chat_message(role, avatar=avatar):
#         st.markdown(msg.content)

# # ============================================================================
# # INPUT Y RESPUESTA
# # ============================================================================

# pregunta = st.chat_input("ğŸ’¬ Escribe tu consulta aquÃ­...")

# if pregunta:
#     # Mostrar mensaje del usuario
#     with st.chat_message("user", avatar="ğŸ‘¤"):
#         st.markdown(pregunta)
    
#     # Agregar al historial
#     st.session_state.mensajes.append(HumanMessage(content=pregunta))
    
#     # Generar respuesta
#     try:
#         with st.chat_message("assistant", avatar="ğŸ¤–"):
#             response_placeholder = st.empty()
#             full_response = ""
            
#             # Obtener historial formateado (fijo en 10 mensajes)
#             historial_formateado = obtener_historial_formateado(10)
            
#             # Streaming de respuesta
#             with st.spinner("FerChus estÃ¡ pensando..."):
#                 for chunk in cadena.stream({
#                     "mensaje": pregunta,
#                     "historial": historial_formateado
#                 }):
#                     full_response += chunk.content
#                     response_placeholder.markdown(full_response + "â–Œ")
            
#             # Mostrar respuesta final
#             response_placeholder.markdown(full_response)
        
#         # Agregar respuesta al historial
#         st.session_state.mensajes.append(AIMessage(content=full_response))
#         st.session_state.contador_mensajes += 1
        
#         # Limitar historial automÃ¡ticamente (mantener Ãºltimos 20 mensajes + sistema)
#         if len(st.session_state.mensajes) > 21:
#             mensaje_sistema = st.session_state.mensajes[0]
#             st.session_state.mensajes = [mensaje_sistema] + st.session_state.mensajes[-20:]
    
#     except Exception as e:
#         st.error(f"âŒ **Error al generar respuesta:** {str(e)}")
#         st.info("ğŸ’¡ Verifica tu conexiÃ³n y configuraciÃ³n de API key")
#         # Remover el Ãºltimo mensaje del usuario si hubo error
#         st.session_state.mensajes.pop()

# # ============================================================================
# # FOOTER
# # ============================================================================

# st.divider()
# st.caption("ğŸ« Colegio Pio XII - DespeÃ±aderos")