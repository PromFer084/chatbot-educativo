from langchain_openai import ChatOpenAI
from langchain.schema import AIMessage, HumanMessage, SystemMessage
import streamlit as st #le asignamos un alias es streamlit
from langchain.prompts import PromptTemplate
import streamlit as st


# #Conf la pagina de la app
st.set_page_config(page_title="Chatbot Educativo ", page_icon="ü§ñ") 
st.title("ü§ñ Chat para el COLEGIO PIO XII - Despe√±aderos-")
st.markdown("Este es un *chatbot escolar* . ¬°Arranquemos!") #a√±adimos descripcion txt

#agregamos una barra para configurar TEMPERATURA Y LLM A ELEGIR
with st.sidebar:
    st.header("Configuraci√≥n")
    temperature = st.slider("Creatividad", 0.0, 1.0, 0.5, 0.1)
    model_name = st.selectbox("Modelo", ["gpt-4", "gpt-4o-mini", "gpt-5"])

#configuramos y definimos el modelo
    chat_model = ChatOpenAI(model=model_name, temperature=temperature)


#Memoria, implementacion
#1-comprobar si hay mensajes
if "mensajes" not in st.session_state:
    st.session_state.mensajes = []

 #  Bot√≥n para limpiar historial
if st.button("üßπ Nueva conversaci√≥n"):
    st.session_state.mensajes = ""
    st.success("Historial limpiado correctamente ‚úÖ")
    st.rerun()

#creamos el template
prompt_template = PromptTemplate(
    input_variables=["mensaje", "historial"],
    template="""
Eres un asistente √∫til, amigable y profesional llamado ChatBoti. 
Tu objetivo es ayudar al usuario de forma clara, emp√°tica y precisa, 
manteniendo coherencia con el contexto previo.

Historial de conversaci√≥n:
{historial}

Usuario: {mensaje}

ChatBot Pro:"""
)

#cremos la cadena
cadena = prompt_template|chat_model

#si hay mensajes previos, los mostramos en la interfaz
for msg in st.session_state.mensajes:
    rol = "assistant" if isinstance(msg, AIMessage) else "user" if isinstance(msg, HumanMessage) else "system"
    with st.chat_message(rol):
        st.markdown(msg.content)

#cuadro de entrada de txt de usuario
pregunta = st.chat_input("Escribe tu mensaje: ")

# if pregunta:
#     #mostramos el mensaje por pantalla
#     with st.chat_message("user"):
#         st.markdown(pregunta)
    #almacenamos en la memoria
    # st.session_state.mensajes.append(HumanMessage(content=pregunta))

    #generar la respuesta usando el llm
    # respuesta = chat_model.invoke(st.session_state.mensajes)

    #mostrar la rta en la interfaz
    
    # with st.chat_message("assistant"):
    #     st.markdown(respuesta.content)

    # #lo a√±ado a la memoria
    # st.session_state.mensajes.append(respuesta) 

if pregunta:
    with st.chat_message("user"):
        st.markdown(pregunta)
    
    try:
        with st.chat_message("assistant"):
            response_placeholder = st.empty() #contenedor vacio
            full_response = ""
 
            # ¬°Aqu√≠ est√° la magia del streaming!
            for chunk in cadena.stream({"mensaje": pregunta, "historial": st.session_state.mensajes}):
                full_response += chunk.content
                response_placeholder.markdown(full_response + "‚ñå")  # El cursor parpadeante
            
            response_placeholder.markdown(full_response)
        
        # No olvides almacenar los mensajes
        st.session_state.mensajes.append(HumanMessage(content=pregunta))
        st.session_state.mensajes.append(AIMessage(content=full_response))
        
    except Exception as e:
        # ¬øQu√© tipo de errores podr√≠an ocurrir aqu√≠?
        st.error(f"Error al generar respuesta: {str(e)}")
        st.info("Verifica que tu API Key de OpenAI est√© configurada correctamente.")

# FOOTER
st.divider()
st.caption("üè´ Colegio Pio XII - Despe√±aderos")       














# import os
# from langchain_openai import ChatOpenAI
# from langchain.schema import AIMessage, HumanMessage, SystemMessage
# import streamlit as st
# from langchain.prompts import PromptTemplate

# # ============================================================================
# # CONFIGURACI√ìN INICIAL
# # ============================================================================

# st.set_page_config(
#     page_title="Chatbot Escolar - Colegio Pio XII",
#     page_icon="ü§ñ",
#     layout="centered",
#     initial_sidebar_state="expanded"
# )

# # ============================================================================
# # FUNCIONES AUXILIARES
# # ============================================================================

# def inicializar_sesion():
#     """Inicializa el estado de la sesi√≥n con valores por defecto"""
#     if "mensajes" not in st.session_state:
#         st.session_state.mensajes = [
#             SystemMessage(content=(
#                 "Eres FerChus, un asistente educativo del Colegio Pio XII en Despe√±aderos, C√≥rdoba. "
#                 "Eres amigable, paciente y ayudas con dudas escolares de todas las materias. "
#                 "Respondes de forma clara, did√°ctica y motivadora."
#             ))
#         ]
#     if "contador_mensajes" not in st.session_state:
#         st.session_state.contador_mensajes = 0


# def obtener_historial_formateado(max_mensajes=10):
#     """
#     Formatea el historial de mensajes para el prompt.
#     Limita a los √∫ltimos N mensajes para no exceder tokens.
#     """
#     mensajes_recientes = st.session_state.mensajes[-max_mensajes:]
#     historial = []
    
#     for msg in mensajes_recientes:
#         if isinstance(msg, SystemMessage):
#             continue
#         elif isinstance(msg, HumanMessage):
#             historial.append(f"Estudiante: {msg.content}")
#         elif isinstance(msg, AIMessage):
#             historial.append(f"FerChus: {msg.content}")
    
#     return "\n".join(historial) if historial else "No hay conversaci√≥n previa."


# def limpiar_conversacion():
#     """Reinicia la conversaci√≥n manteniendo solo el mensaje de sistema"""
#     mensaje_sistema = st.session_state.mensajes[0]
#     st.session_state.mensajes = [mensaje_sistema]
#     st.session_state.contador_mensajes = 0


# def validar_api_key():
#     """Verifica que la API key de OpenAI est√© configurada"""
#     if not os.getenv("OPENAI_API_KEY"):
#         st.error("‚ö†Ô∏è **Error:** No se encontr√≥ OPENAI_API_KEY en las variables de entorno")
#         st.info("üí° Configura tu API key antes de usar el chatbot")
#         st.code("export OPENAI_API_KEY='tu-api-key-aqui'", language="bash")
#         st.stop()

# # ============================================================================
# # INTERFAZ PRINCIPAL
# # ============================================================================

# # ============================================================================
# # INICIALIZACI√ìN TEMPRANA (antes del sidebar)
# # ============================================================================

# inicializar_sesion()

# # T√≠tulo y descripci√≥n
# st.title("ü§ñ Chat Educativo - Colegio Pio XII")
# st.markdown("**Despe√±aderos, C√≥rdoba** | Asistente: *FerChus* üìö")
# st.divider()

# # ============================================================================
# # SIDEBAR - CONFIGURACI√ìN
# # ============================================================================

# with st.sidebar:
#     st.header("‚öôÔ∏è Configuraci√≥n")
    
#     # Bot√≥n de reset (siempre en la parte superior)
#     if st.button("üßπ Nueva conversaci√≥n", key="reset_btn", use_container_width=True):
#         limpiar_conversacion()
#         st.rerun()
    
#     st.divider()
    
#     # Configuraci√≥n del modelo
#     temperature = st.slider(
#         "üí° Creatividad",
#         min_value=0.0,
#         max_value=1.0,
#         value=0.7,
#         step=0.1,
#         help="Mayor valor = respuestas m√°s creativas"
#     )
    
#     model_name = st.selectbox(
#         "ü§ñ Modelo",
#         options=["gpt-4o-mini", "gpt-4o"],
#         index=0,
#         help="gpt-4o-mini es m√°s r√°pido y econ√≥mico"
#     )
    
#     st.divider()
    
#     # Estad√≠sticas
#     st.caption("üìä **Estad√≠sticas**")
#     num_mensajes = len([m for m in st.session_state.mensajes if not isinstance(m, SystemMessage)])
#     st.caption(f"üí¨ Mensajes: {num_mensajes // 2}")

# # ============================================================================
# # VALIDACI√ìN Y CONFIGURACI√ìN DEL MODELO
# # ============================================================================

# validar_api_key()

# # Crear prompt template optimizado
# prompt_template = PromptTemplate(
#     input_variables=["mensaje", "historial"],
#     template="""Eres FerChus, un asistente educativo amigable del Colegio Pio XII.

# Contexto de la conversaci√≥n:
# {historial}

# Pregunta del estudiante: {mensaje}

# Responde de manera clara, did√°ctica y motivadora. Si es un tema complejo, usa ejemplos."""
# )

# # Crear modelo y cadena
# try:
#     chat_model = ChatOpenAI(model=model_name, temperature=temperature)
#     cadena = prompt_template | chat_model
# except Exception as e:
#     st.error(f"‚ùå Error al inicializar el modelo: {str(e)}")
#     st.stop()

# # ============================================================================
# # MOSTRAR HISTORIAL
# # ============================================================================

# for msg in st.session_state.mensajes:
#     if isinstance(msg, SystemMessage):
#         continue
    
#     role = "assistant" if isinstance(msg, AIMessage) else "user"
#     avatar = "ü§ñ" if role == "assistant" else "üë§"
    
#     with st.chat_message(role, avatar=avatar):
#         st.markdown(msg.content)

# # ============================================================================
# # INPUT Y RESPUESTA
# # ============================================================================

# pregunta = st.chat_input("üí¨ Escribe tu consulta aqu√≠...")

# if pregunta:
#     # Mostrar mensaje del usuario
#     with st.chat_message("user", avatar="üë§"):
#         st.markdown(pregunta)
    
#     # Agregar al historial
#     st.session_state.mensajes.append(HumanMessage(content=pregunta))
    
#     # Generar respuesta
#     try:
#         with st.chat_message("assistant", avatar="ü§ñ"):
#             response_placeholder = st.empty()
#             full_response = ""
            
#             # Obtener historial formateado (fijo en 10 mensajes)
#             historial_formateado = obtener_historial_formateado(10)
            
#             # Streaming de respuesta
#             with st.spinner("FerChus est√° pensando..."):
#                 for chunk in cadena.stream({
#                     "mensaje": pregunta,
#                     "historial": historial_formateado
#                 }):
#                     full_response += chunk.content
#                     response_placeholder.markdown(full_response + "‚ñå")
            
#             # Mostrar respuesta final
#             response_placeholder.markdown(full_response)
        
#         # Agregar respuesta al historial
#         st.session_state.mensajes.append(AIMessage(content=full_response))
#         st.session_state.contador_mensajes += 1
        
#         # Limitar historial autom√°ticamente (mantener √∫ltimos 20 mensajes + sistema)
#         if len(st.session_state.mensajes) > 21:
#             mensaje_sistema = st.session_state.mensajes[0]
#             st.session_state.mensajes = [mensaje_sistema] + st.session_state.mensajes[-20:]
    
#     except Exception as e:
#         st.error(f"‚ùå **Error al generar respuesta:** {str(e)}")
#         st.info("üí° Verifica tu conexi√≥n y configuraci√≥n de API key")
#         # Remover el √∫ltimo mensaje del usuario si hubo error
#         st.session_state.mensajes.pop()

# # ============================================================================
# # FOOTER
# # ============================================================================

# st.divider()
# st.caption("üè´ Colegio Pio XII - Despe√±aderos")